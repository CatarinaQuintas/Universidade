<header class="banner">
<svg xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:svg="http://www.w3.org/2000/svg" xmlns="http://www.w3.org/2000/svg" xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape" version="1.1" id="svg2" xml:space="preserve" sodipodi:docname="EC-C.eps" viewBox="0 0 529.13 264.57"><metadata id="metadata8"><rdf:RDF><cc:Work rdf:about=""><dc:format>image/svg+xml</dc:format><dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/></cc:Work></rdf:RDF></metadata><defs id="defs6"/><sodipodi:namedview pagecolor="#ffffff" bordercolor="#666666" borderopacity="1" objecttolerance="10" gridtolerance="10" guidetolerance="10" inkscape:pageopacity="0" inkscape:pageshadow="2" inkscape:window-width="640" inkscape:window-height="480" id="namedview4"/><g id="g10" inkscape:groupmode="layer" inkscape:label="ink_ext_XXXXXX" transform="matrix(1.3333333,0,0,-1.3333333,0,468.32)"><g id="g12" transform="scale(0.1)">
         <!-- uminho symbol + red background -->
         <path d="M 0,1528.15 H 1984.25 V 3512.4 H 0 V 1528.15" style="fill:#a42a3c;fill-opacity:1;fill-rule:nonzero;stroke:none" id="path14"/>
         <!-- uminho symbol -->
         <path d="m 1502.43,2751.68 -378.95,-220.62 c -68.8,-39.71 -129.285,64.76 -60.48,104.49 l 379,220.52 c 68.88,39.76 129.16,-64.71 60.43,-104.39 m -1039.617,-1.46 383.14,-217.25 c 68.711,-39.66 129.059,64.89 60.172,104.67 L 522.922,2854.8 c -68.77,39.7 -128.938,-64.84 -60.109,-104.58 m 459.449,-797.92 -0.047,440.75 c 0,33.37 27.109,60.33 60.379,60.33 33.336,0 60.336,-27.01 60.336,-60.34 l -0.05,-440.74 c 0,-33.28 -26.92,-60.34 -60.286,-60.33 -33.321,0 -60.332,27.01 -60.332,60.33 m -379.258,235.44 184.039,104.36 c 68.863,39.77 8.461,144.3 -60.289,104.6 L 482.758,2292.24 c -68.774,-39.72 -8.574,-144.24 60.246,-104.5 m 918.046,-3.45 -179.19,108.08 c -68.78,39.7 -8.28,144.18 60.55,104.43 l 179.14,-108.16 c 68.72,-39.67 8.4,-144.12 -60.5,-104.35 m -478.495,964.28 c -33.371,0 -60.293,-27.05 -60.293,-60.33 l -0.047,-211.59 c 0,-33.32 27.012,-60.34 60.34,-60.34 33.265,0 60.375,26.98 60.375,60.34 l -0.05,211.59 c 0,33.32 -27,60.33 -60.325,60.33" style="fill:#ffffff;fill-opacity:1;fill-rule:nonzero;stroke:none" id="path16"/>
         <!-- ec symbol + blue background -->
         <path d="M 1984.25,1528.15 H 3968.51 V 3512.4 H 1984.25 V 1528.15" style="fill:#8cbce8;fill-opacity:1;fill-rule:nonzero;stroke:none" id="path22"/>
         <!-- ec symbol -->
         <path d="m 3540.85,2274.8 -100.97,183.1 c -39.72,68.79 -144.26,8.6 -104.58,-60.12 l 101.07,-183.06 c 39.74,-68.84 144.12,-8.57 104.48,60.08 m -17.75,558.93 c 0,33.34 -27.02,60.24 -60.29,60.24 l -211.41,0.05 c -33.3,0 -60.28,-27 -60.28,-60.29 0,-33.25 26.94,-60.34 60.28,-60.34 l 211.41,0.05 c 33.31,0 60.29,26.99 60.29,60.29 m -362.52,-738.96 c 16.65,28.85 6.78,65.71 -22.07,82.36 -28.87,16.67 -65.68,6.72 -82.31,-22.09 l -105.75,-183.06 c -16.65,-28.84 -6.77,-65.71 22.07,-82.36 28.79,-16.62 65.73,-6.83 82.4,22.04 z m -150.24,974.55 c 16.66,28.85 6.77,65.71 -22.06,82.36 -28.88,16.67 -65.69,6.72 -82.32,-22.09 l -105.75,-183.06 c -16.65,-28.84 -6.76,-65.71 22.07,-82.36 28.8,-16.62 65.73,-6.83 82.4,22.05 z m -241.49,-862.5 c 0,33.25 -26.96,60.34 -60.29,60.34 l -211.42,-0.05 c -33.29,0 -60.29,-27 -60.29,-60.29 -0.01,-33.35 27.04,-60.24 60.29,-60.24 l 211.4,-0.05 c 33.31,0 60.31,26.99 60.31,60.29 M 2622,2635.57 2516.25,2818.63 c -16.63,28.81 -53.44,38.76 -82.31,22.09 -28.84,-16.65 -38.72,-53.51 -22.07,-82.36 l 105.66,-183.1 c 16.67,-28.88 53.61,-38.67 82.4,-22.05 28.83,16.65 38.72,53.52 22.07,82.36" style="fill:#ffffff;fill-opacity:1;fill-rule:nonzero;stroke:none" id="path24"/>
      </g>
    </g>
  </svg>
</header>

# BibTeXPro, Um processador de BibTeX

**Instituição:** Universidade do Minho

**Cadeira:** Processamento de Linguagens e Compiladores (2021/2022)

**Identificação:** plc21TP1gr03

**Equipa**
: [Alef Keuffer](https://github.com/Alef-Keuffer/) (A91383)
: [Ivo Lima](https://github.com/IvoLims) (A90214)
: [Catarina Quintas](https://github.com/CatarinaQuintas) (A91650)


## O formato $Bib\TeX$

$Bib\TeX$ é a ferramenta e formato de ficheiro usado para descrever e processar listas de referências, principalmente em conjunção com $La\TeX$.

### Entrada $Bib\TeX$

Uma entrada $Bib\TeX$ consiste em um **tipo de entrada**, uma **chave de citação** e um número de **campos** que definem várias caraterísticas de uma entrada específica.[^format].

Existem 17 tipos de entrada, sendo 14 categorias de referência e 3 de uso específico em $Bib\TeX$.

As entradas não são _case sensitive_^[https://tex.stackexchange.com/questions/163687/is-there-a-preferred-capitalization-style-for-reference-types-in-bibtex-biblatex].

A documentação diz que ficheiros $Bib\TeX$ podem conter 4 tipos de entrada: `@string`, `@preamble`, `@comment` e 14 categorias (e.g. `@article`, `@book`, etc)[^format].

[^format]: http://www.bibtex.org/Format/

Note que:

`@string`
  : define abreviações que podem se usadas depois em um campo.

`@preamble`
  : define como um texto especial deve ser formatado.

`@comment`
  : para comentários que não devem ser levados em conta pelo $Bib\TeX$.

Estas três não seram processadas pelo nosso programa.

## Especificação da Solução

A nossa solução deve satisfazer os seguintes requisitos<a name="req"></a>:

(R1)<a name="R1"></a>
: Fazer a contagem das categorias presentes no documento, tais como: _phDThesis_, _Misc_, _InProceeding_, etc.

(R2)<a name="R2"></a>
: Produzir um documento em formato _HTML_ com <a name="R21"></a>(R2.1) o nome das categorias encontradas e <a name="R22"></a>(R2.2) respectivas contagens.

(R3)<a name="R3"></a>
: Filtrar, para cada entrada de cada categoria, a respetiva <a name="R31"></a>(R3.1) chave, <a name="R32"></a>(R3.2) autores e <a name="R33"></a>(R3.3) título. <a name="R34"></a>(R3.4) O resultado final deverá ser incluído no documento _HTML_ gerado em [(R2)](#R2).

(R4)<a name="R4"></a>
: Criar um índice de autores, que mapeie cada autor nos respectivos registos, de modo a que posteriormente uma ferramenta de procura do Linux possa fazer a pesquisa.

(R5)<a name="R5"></a>
: Construir um Grafo que mostre, para um dado autor (definido à partida) todos os autores que publicam normalmente com o autor em causa.

(R6)<a name="R6"></a>
: Recorrendo à linguagem _Dot_ do _GraphViz_, gerar um ficheiro com o grafo de [(R5)](#R5) de modo a que possa, posteriormente, usar uma das ferramentas que processam _Dot_ para desenhar o dito grafo de associações de autores.

## Execução do programa

Para realizar as modificações no ficheiro usamos `solve(author_name,INPUT_FILENAME=BIB_EXAMPLE_FILENAME)`, passando como argumento o nome do autor que queremos conforme [(R5)](#R5).

```python, echo = False
#!/usr/bin/python
```

## Módulo não é `re`

Usamos o módulo `regex` que é um _superset_ de `re` mais poderoso. Seu uso será justificado.

```python
import regex as re
```

## Algumas constantes

Aqui incluimos _MathJax_, uma biblioteca em _javascript_, para renderizar fórmulas matemáticas nos navegadores.

```python
MATHJAX = '''
            <script type="text/x-mathjax-config">
                MathJax.Hub.Config({
                    "extensions":["tex2jax.js"],
                    "jax":["input/TeX",
                           "output/HTML-CSS"],
                    "messageStyle":"none",
                    "tex2jax":{
                        "processEnvironments":false,
                        "processEscapes":true,
                        "inlineMath":[["$","$"]],
                        "displayMath":[]
                    },
                    "TeX":{
                        "extensions":["AMSmath.js",
                                      "AMSsymbols.js",
                                      "noErrors.js",
                                      "noUndefined.js"]
                    },
                    "HTML-CSS":{
                        "availableFonts":["TeX"]
                    }
                });
            </script>

            <script type="text/javascript" async
                src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js">
            </script>
'''
```

O início do nosso _HTML_ é

```python
HTML_PROLOGUE = f'''<!DOCTYPE  html>
    <HTML lang="en">
        <HEAD>
            <meta charset="utf-8">
            <TITLE>Categories in BibTeX</TITLE>
            {MATHJAX}
        </HEAD>'''
```

Vamos ter que fechar a tag _HTML_ que começamos em `HTML_PROLOGUE`:

```python
HTML_EPILOGUE = '</HTML>'
```

O ficheiro dado como argumento de entrada é o ficheiro `exemplo-utf8.bib`.

```python
BIB_EXAMPLE_FILENAME = "exemplo-utf8.bib"
```

Decidimos nomear o output `output.html`.

```python
OUTPUT_FILENAME = 'output.html'
```

## Função principal


Em `solve()` temos a váriavel `html_str_ls` que consiste numa lista de _strings_ que serão concatenadas. A título de optimização da imutabilidade de _strings_ (concatenação de _strings_ em _python_ cria uma cópia de cada), optamos por fazer sucessivos _appends_ de custo $\cal{O}(1)$ e por fim, concatena-las para formar o código _HTML_.

Em `bib_str` guardamos todo o texto contido em `INPUT_FILENAME`.

```python, wrap=True
def solve(author_name,INPUT_FILENAME=BIB_EXAMPLE_FILENAME):
    html_str_ls = [HTML_PROLOGUE]
    bib_str = get_bib_str(INPUT_FILENAME)

    entries = get_entries(bib_str)
    format_authors(entries)
    fix_repeated_authors(entries)

    html_str_ls.append(
        html_enclose('body',
            get_html_pub_type_counts(entries)
            + get_html_common_pub_author(author_name,entries)
            + get_html_pub_type_index(entries)
            + get_html_author_index(entries)))

    html_str_ls.append(HTML_EPILOGUE)
    with open(OUTPUT_FILENAME,'w') as file:
        file.write('\n'.join(html_str_ls))
```

`get_bib_str()` é utilizada para abrir e extrair o conteúdo do ficheiro.

```python
def get_bib_str(filename):
    with open(filename,'r') as file:
        return file.read()
```

## Recolhendo as entradas

Neste procedimento, criamos um dicionário onde cada chave é um par (categoria de publicação, nome do autor) e o valor é um dicionário em que cada chave é um campo da entrada $Bib\TeX$ e o valor é o valor do campo.


```python, evaluate = False
def get_entries(string):
    d = {}
```

Poderíamos coletar todos os campos de todas as entradas, mas neste trabalho só são relevantes alguns campos. Então, para economizar espaço no dicionário, definimos:

```python, evaluate = False
    RELEVANT_FIELDS = {'author','title'}
```

Como foi dito anteriormente, alguns tipos de entrada não são categorias de referência, assim iremos ignorá-los.

```python, evaluate = False
    SPECIAL_TYPES = {'comment','string','preamble'}
```

É aqui que se justifica o uso do módulo `regex`. Note a expressão regular:

```python, evaluate = False
    between_cbrace_ex = r'(?:(?<rec>{(?:[^{}]+|(?P>rec))*+}))'
```

Nela usamos um padrão recursivo não suportado pelo módulo `re`. O padrão é usado para capturar o que está entre chavetas, que podem estar aninhadas arbitrariamente.


```python, evaluate = False
    field_match = re.compile(
        rf"(?<name>\w+)\s*=\s*("
        rf"(?<value>{between_cbrace_ex})"
        rf'|"(?<value>[^"]+)"'
        rf"|(?<value>\d+))"
    )
    entry_match = re.compile(rf'@(?<type>\w+)(?<value>{between_cbrace_ex})')
    key_match = re.compile(r'([^{},~#%\\]+),')

    for entry in entry_match.finditer(string):
        entry_type = entry['type'].lower()
        if entry_type not in SPECIAL_TYPES:
            key = key_match.search(entry['value'])[1]
            d[entry_type, key] = {
                field['name'].lower(): field['value']
                for field in field_match.finditer(entry['value'])
                if field['name'].lower() in RELEVANT_FIELDS
            }

    return d
```

## Procedimentos usados ao longo do programa

### Relacionados a expressões $La\TeX$

#### Chavetas

Assumimos que as chavetas estão balanceadas.

Chavetas dentro de títulos são usadas para prevenir que palavras sejam convertidas em letras minúsculas (se "sentence style" é usado ao invés de "title style")^[https://tex.stackexchange.com/questions/109064/is-there-a-difference-between-and-in-bibtex:].

Por exemplo, devemos usar chavetas para escrever

`title = "The Life of {Albert} {Einstein}"`

ou, de forma equivalente,

`title = {The life of {Albert} {Einstein}}`

se quisermos garantir que as letras 'A' e 'E' sejam sempre formatadas em letras maiúsculas mesmo que "sentence style" esteja sendo usado.

Suspeitamos que talvez pudessemos usar:

```py
r'[^\\]\$.*[^\\]\$'
```

para identificar que não estamos dando _escape_ no _dollar sign_. Mas já tinhamos esse procedimento feito e decidimos por não alterá-lo.

<a name="unbrace"></a>


```python
def unbrace(expression):
    string_ls = []
    is_between_dollar_sign = False
    is_previous_backslash = False
    for c in expression:
        if c == '$' and not is_previous_backslash:
            if is_between_dollar_sign:
                is_between_dollar_sign = False
            else:
                is_between_dollar_sign = True
        if c == '\\':
            is_previous_backslash = True
        else:
            is_previous_backslash = False
        if c in '{}' and not is_between_dollar_sign:
            continue
        string_ls.append(c)
    return ''.join(string_ls)
```

### Relacionados a _HTML_

É muito comum em _HTML_ o uso de _tags_ para marcar uma expressão. Então, criamos um procedimento que facilita cercar uma expressão pela _tag_ desejada.

```python
def html_enclose(tag,string):
    return rf'<{tag.upper()}>{string}</{tag.upper()}>'
```

Nesse sentido, _spans_ são muito úteis em _HTML_, logo criamos:

```python
def html_create_span(expression):
    return html_enclose('span',expression)
```

Às vezes queremos adicionar um atributo numa _tag_, nesse caso podemos usar (há um pequeno problema com esse procedimento, mas para nosso uso não foi relevante):

```python
def html_add_attr(attr, val, html_expression):
    return re.sub(
        r"<(\w+)([^>]*)\s*>(.*)</\1>",
        rf'<\1\2 {attr.upper()}="{val}">\3</\1>',
        html_expression,
    )
```

### Relacionados a _Regex_

Em certas ocasiões, desejamos fazer várias substituições seguidas numa _string_, logo criamos:

```python
def mult_replace(string, replacement_list):
    for old, new in replacement_list:
        string = re.sub(old, new, string)
    return string
```

## Tratamento do nome dos autores

Escolhemos remover acentuações e caráteres especiais que as representam em $La\TeX$ (e.g. `\~`) do nome dos autores.

É importante notar que ainda ocorrem alguns problemas de acentuações uma vez que não removemos acentuações do tipo `\~{}`.

```python
def format_authors(data):
    for d in data.values():
        if "author" in d:
            author_lst = [ remove_consecutive_spaces(
                           str.strip(
                           invert_name(
                           unbrace(
                           remove_accents(name)))))

                           for name in re.split(r"\band\b",
                                                d["author"].replace("\n", " "))]
            d['author'] = [author for author in author_lst if author]
```

### Procedimentos auxiliares

```python
def remove_consecutive_spaces(name):
    return re.sub(r'\s+',' ',name)
```

#### Inversão das componentes do nome

Para inverter nomes do tipo: last_name, first_name. Por exemplo: "da Cruz, Daniela" → "Daniela da Cruz"

```python
def invert_name(author_name):
    return re.sub(r"([^,]+),\s*([^,]+)", r"\2 \1", author_name)
```

#### Remoção de acentuações

Relevante nesse sentido é o _script_ achado em [LaTex-handler](https://github.com/hayk314/LaTex-handler) ou tabelas encontradas [aqui](#https://stackoverflow.com/questions/4578912/replace-all-accented-characters-by-their-latex-equivalent).

```python
def remove_accents(name):
    return remove_latex_accent(remove_normal_accent(name))
```

Para remoção de acentos $La\TeX$ consultamos a [wiki](https://en.wikibooks.org/wiki/LaTeX/Special_Characters).

Pensamos em possivelmente usar algo como (1 a 2 pelo caso `\t{oo}`, `SYMBOL` é um caráter relevante):

```py
re.sub(r'(?(?={)(SYMBOL){(\w{1,2})}|(\w))',
       lambda m: fix_accent(m[1],m[2]),
       author_name)
```

para manter acentuações, mas devido a restrições de tempo não achamos prudente embarcar nesta ideia.

```python
def remove_latex_accent(name):
    return re.sub(r'\\\W(?:{(.*)})?',
                  '\1',
                  name)
```

Aqui removemos palavras com acentuações normais, isto é, palavras como "á", "é", "í", etc (não $La\TeX$).

```python
def remove_normal_accent(name):
    import unicodedata

    return "".join(
        (
            c
            for c in unicodedata.normalize("NFD", name)
            if unicodedata.category(c) != "Mn"
        )
    )

```

Também usamos a já referenciada [`unbrace()`](#unbrace).

## Tratando autores repetidos na estrutura

No dicionário, teremos autores repetidos (pois podem estar escritos de formas diferentes, omitindo alguns sobrenomes ou até mesmo primeiros nomes).

Por exemplo, 'M. J. Varanda', 'M. Joao Varanda', 'Maria Joao Varanda' e 'Maria Joao V. Pereira' são diferentes maneiras de se referir a mesma pessoa.

```python
def fix_repeated_authors(data):
    author_blocks = fix_block_func(
                        block_authors_with_two_common_names_v2(
                            get_author_list(data)))

    author_dict = {author_name:max(s,key=len)
                   for s in author_blocks
                   for author_name in s}

    for d in data.values():
        d['author'] = [author_dict[author]
                       for author in d['author']]
```

Para lidar com isso, realizamos três procedimentos:

1. Obtemos uma lista dos autores ordenada alfabeticamente.
2. Criamos conjuntos onde os seus elementos representam um mesmo autor. Ou seja, se temos três nomes: $A$, $B$ e $C$ e temos os conjuntos $\{A,B\}$ e $\{B,C\}$, então os nomes $A,B,C$ referem-se ao mesmo autor.
3. Juntamos esses blocos para que cada bloco seja um único autor. Ou seja, determinamos uma "transitividade" nos blocos, usando o exemplo anterior, se temos $\{A,B\}$ e $\{B,C\}$, devemos obter $\{A,B,C\}$.

### Procedimento 1

```python
def get_author_list(data):
    return sorted(set([a
                       for s in data.values()
                       for a in s.get("author", [])]))
```

### Procedimento 2

```python, evaluate = False
def block_authors_with_two_common_names_v2(authors):
    res = set()
    for author in authors:
        fs = set()
        for author2 in authors:
            a1 = set(re.findall(r'\w\w+',author))
            a2 = set(re.findall(r'\w\w+',author2))
```

Se os autores tem mais de duas componentes do nome em comum, então podemos considera-los o mesmo autor.

```python, evaluate = False
            if len(a1.intersection(a2)) > 1:
                fs.add(author2)
```

Para lidar com a situação descrita abaixo, assumimos que a primeira componente de um nome nunca será omitida.

Caso especial: Suponha que existe um autor que só tem uma componente do nome não abreviada (e.g. P. Henriques). Suponha que outro autor (e.g. P.R. Henriques) também só tem uma componente do nome não abreviada e essa componente é igual a do primeiro autor. Então ainda temos que fortalecer a condição para que sejam considerados iguais. Para isso, usamos [`is_a_first_last_match()`](#is_a_first_last_match) garantindo que pelo menos a abreviação da primeira componente dos nomes sejam iguais.

```python, evaluate = False
            elif (
                len(a1) == 1
                and len(a1.intersection(a2)) == 1
                and is_a_first_last_match(author, author2)
            ):
                fs.add(author2)
        res.add(frozenset(fs))
    return res
```

Pra implementar [`is_a_first_last_match()`](#is_a_first_last_match) usamos `get_crude_abbrev()` para obter uma string com o primeiro caráter de cada componente do nome de um autor (e.g. "Ricardo Henriques → RH").

```python
def get_crude_abbrev(name):
    return ''.join(c for c in name if c.isupper())
```

Aqui iremos verificar se os primeiros caráteres da primeira e última componente do nome de um autor $a_1$ são iguais, respetivamente, aos primeiros e últimos caráteres da primeira e última componente do nome de um autor $a_2$.

<a name="is_a_first_last_match"></a>

```python
def is_a_first_last_match(author1,author2):
    a1 = get_crude_abbrev(author1)
    a2 = get_crude_abbrev(author2)
    return a1[0] == a2[0] and a1[-1] == a2[-1]
```

### Procedimento 3

Objetivo: Criar a "transitividade" nos blocos dos autores referenciada no ínicio.

```python
def fix_block_func(data):
    res = set()
    for q in data:
        for s2 in data:
            if q.intersection(s2) != set():
                q = q.union(s2)
        res.add(frozenset(q))
    return res
```

## Contagem dos tipos de publicações

Conforme [(R1)](#R1), devemos contar quantas publicações de cada tipo existem.

```python
def get_pub_type_counts(data):
    pub_types_occur = [x[0] for x in data.keys()]
    pub_types = set(pub_types_occur)
    return [(pub_type, pub_types_occur.count(pub_type)) for pub_type in pub_types]
```

Conforme [(R2)](#R2) queremos incorporar a contagem de publicações de cada tipo no documento _HTML_ que iremos produzir.

```python
def get_html_pub_type_counts(data):
    string_ls = [
        html_enclose(
            "h2",
            "Number of Occurrences of Publication Types",
        )
    ]
    pub_counts = sorted(
        get_pub_type_counts(data),
        key=lambda x: x[1],
        reverse=True,
    )

    time = lambda v: "s" if v > 1 else ""
    for pub_type, count in pub_counts:
        string_ls.append(
            html_enclose(
                "p",
                f"Type {pub_type} appears {count} time{time(count)}",
            )
        )

    return "\n".join(string_ls)
```

### Solução inicial

A estratégia para satisfazer [(R1)](#R1) consistiu em ler o arquivo linha a linha verificando se a categoria encontrada já aparecia no dicionário, se já existir, irá ser incrementado o número de ocorrências, senão será adicionado como primeira ocorrência, para que depois possa ser produzido um ficheiro _HTML_ com todas as categorias e o devido número de ocorrências.

De seguida apresentamos a Expressão Regular utilizada para filtrar a informação pedida em [(R1)](#R1).

Uma vez que todas as categorias num $Bib\TeX$ têm como antecedente o caráter `@` e terminam numa `{`, tornou-se fácil criar um filtro que guarde toda a informação delimitada entre esses dois parâmetros.

Através dessa pequena realização chegamos à seguinte expressão: `r'^@(.*){'`

```py
import re

file = open("exemplo-utf8.bib", "r")
read = True
dic = {}
string_ls = ['<!DOCTYPE  HTML PUBLIC>\n<HTML>\n   <HEAD>\n      '\
             '<TITLE>Categories in BibTeX</TITLE>\n   </HEAD>\n   <BODY>']
while read:
    linhaFicheiro = file.readline()
    ncat = re.match(r'^@(.*){',linhaFicheiro)
    if ncat != None:
       cat_title = ncat.group(1).title()
       dic[cat_title] = dic.get(cat_title,0) + 1
    if not linhaFicheiro:
       read = False
       file.close()

time = lambda v: 's' if v > 1 else ''

for k, v in dic.items():
    string_ls.append(f'      <P>The category {k} appears {v} time{time(v)}.</P>')
    string_ls.append(f'   </BODY>\n</HTML>')
with open('output.html','w') as file:
     file.write('\n'.join(string_ls))
```

Infelizmente a estratégia adotada na primeira questão de unicamente guardar aquilo que interessava tornou-se impraticável pois não era escalável para a extração e manipulação necessária dos restantes parâmetros pedidos nas outras questões.

## Criação do grafo

Conforme [(R5)](#R5) queremos construir um grafo que represente a co-autoria entre os autores.

```python
def get_author_pub_graph(author,data):
    pub_partners = []
    for entry in data.values():
        if 'author' in entry and author in entry['author']:
            for partner in entry['author']:
                if partner != author:
                    pub_partners.append(partner)
    return [(author_name,pub_partners.count(author_name))
            for author_name in set(pub_partners)]
```

Conforme [(R6)](#R6) iremos recorrer a linguagem _Dot_ para renderizar o grafo.

```python
def get_dot_graph(author,data):
    import textwrap
    g = sorted(get_author_pub_graph(author,data),key = lambda x: x[1])
    string_ls = ['graph{']
    string_ls2 = []
    for partner_author,no_joint_pub in g[-3:]:
        string_ls2.append(f'"{author}" -- "{partner_author}" [label="{no_joint_pub}"]')
    string_ls.append(textwrap.indent('\n'.join(string_ls2),'  '))
    string_ls.append('}')
    return '\n'.join(string_ls)
```

Como ideia nossa para ir além do que foi pedido, decidimos incorporar o grafo no documento _HTML_ que iremos produzir.

Utilizamos `re.search()` porque o arquivo gerado contém um preâmbulo _XML_ como _doctype_. Só queremos o _SVG_.

```python
def get_html_dot_svg(author,data):
    import os
    DOT_INPUT_FILENAME = 'dot_input'
    with open(DOT_INPUT_FILENAME,'w') as file:
        file.write(get_dot_graph(author,data))
    os.system(f'dot -T svg -O {DOT_INPUT_FILENAME}')
    with open(DOT_INPUT_FILENAME + '.svg','r') as file:
        return re.search(r'<svg(?:.|\n)+</svg>',file.read()).group()
```

Finalmente,

```python
def get_html_common_pub_author(author,data):
    string_ls = [html_enclose('h2','Author Graph')]
    string_ls.append(get_html_dot_svg(author,data))
    return ''.join(string_ls)
```

que é responsável por gerar:

![](auth_graph.png)

na página _HTML_.

## Filtrar (chave,autore,título)

### Títulos

Pelo [(R3.3)](#R33), devemos incluir títulos. Para isso devemos aplicar um tratamento para uma formatação mais elegante (como manter expressões $La\TeX$).

Note que formatamos _small caps_ como pode ser notado em entradas que contém "Camila". Também formatamos _sans serif_ e algumas expressões matemáticas.

```python
def fix_title(title):
    substitutions = [(r'\\textsc{((?:\\{|[^{])+)}',
                      lambda m: f'{html_to_small_caps(html_create_span(m.group(1)))}'),
                     (r'\\textsf{((?:\\{|[^{])+)}',
                      lambda m: f'{html_to_sans_serif(html_create_span(m.group(1)))}'),
                     (r'(\$(?:.|\\\$)+\$)',
                      lambda m: f'{str_to_html_math(m.group(1))}')]


    replace = lambda x: mult_replace(x,substitutions)

    return   html_create_span(
             single_quote_latex(
             double_quote_latex(
             unbrace(
             replace(
             remove_latex_accent(
             unscape_latex(
             ' '.join(s.strip() for s in title.split('\n')))))))))
```

#### Tratamento de caráteres $La\TeX$

##### Aspas

```python
def double_quote_latex(expression):
    return re.sub(r"``(.*[^\\])''",r'"\1"',expression)
```

```python
def single_quote_latex (expression):
    return re.sub(r"[^`]`([^`].*[^'])'[^`]",r"'\1'",expression)
```

##### _Escaped characters_

Alguns caráteres que pode aparecer em títulos e que temos a capacidade de tratar.

```python
def unscape_latex(latex_expression):
    return re.sub(r'\\([&%$#_{}\\])',r'\1',latex_expression)
```

Veja como fica a entrada

```bibtex
@Book{RH02,
     author=   {José Carlos Ramalho and Pedro Rangel  Henriques},
     title =   {XML \& XSL: da teoria à prática},
     .
     .
     .
```

em _HTML_:

![](latex_and.png)

### Formatações especiais

#### Small caps

Usado para converter expressoes latex `\textsc{expression}`

```python
def html_to_small_caps(html_expression):
    return html_add_attr('style','font-variant:small-caps',html_expression)
```

```python
def str_to_html_small_caps(expression):
    return html_to_small_caps(html_create_span(expression))

```

Veja como fica a entrada

```bibtex
@techreport{Barbosa95,
 author = "L.S. Barbosa and J.J. Almeida",
 title  = "System Prototyping in \textsc{Camila}",
 .
 .
 .
```

em _HTML_:

![](serif_camila.png)

#### Sans serif

```python
def html_to_sans_serif(html_expression):
    return html_add_attr('style','font-family:sans-serif',html_expression)
```

Este caso (`\textsf`) não ocorre no exemplo mas achamos interessante adiciona-lo.


#### Matemática

```python
def str_to_html_math(string):
    return html_add_attr('class','math inline',html_create_span(string))
```

Observe como fica a entrada

```bibtex
@InProceedings{lrec06,
  author =       {José João Almeida and Alberto Simões},
  title =        {{$T_2O$} --- Recycling Thesauri into a Multilingual Ontology},
  .
  .
  .
```

em _HTML_:

![](math_html.png)

### Incorporar no documento _HTML_

Como fica renderizado:

![](pub_ind.png)

Conforme [(R3.4)](#R34):

```python
def get_html_pub_type_index(data):
    string_ls = [html_enclose('h2','Publication Type Index')]
    for entry_type in sorted(set(x[0] for x in data)):
        string_ls.append(html_enclose('h3',entry_type))
        for citation_key in [x[1] for x in data if x[0]==entry_type]:
            title = data[entry_type,citation_key].get('title','')
            authors = ', '.join((sorted(data[entry_type,citation_key].get('author',''))))
            string_ls.append(
                html_enclose('p',
                             f"Key = {citation_key}"
                             f"\n<br>Title = {fix_title(title)}"
                             f"\n<br>Autores = {authors}"
                )
            )
    return '\n'.join(string_ls)
```

Correspondendo qundo visto em _HTML_:

![](num_occ_pub_type.png)

## Índice de autores

Conforme [(R4)](#R4) iremos criar um índice de autores.

Geralmente, nos índices de autores, o apelido aparece primeiro seguido pelas iniciais dos outros nomes. Com esse propósito, criamos o procedimento que recebe um nome normalizado (e.g. Pedro Filipe H. Pereira), retornando-o "invertido" e abreviado (e.g. Pereira, P. F. H.).

```python
def last_name_first(name):
    initials =  '. '.join(get_crude_abbrev(name))[:-2]
    last_name = name.split()[-1]
    return f'{last_name}, {initials}'
```

Utilizamos `last_name_first()` na construção de um dicionário que irá conter como chaves o nome do autor já formatado e como valor todas as chaves de citações de suas publicações.

```python
def get_author_index_dict(data):
    index = {}
    for key, e in data.items():
        if 'author' in e:
            for author in e['author']:
                author_name = last_name_first(author)
                if author_name not in index:
                    index[author_name] = set()
                index[author_name].add(key[1])
    return index
```

Decidimos incorporar o índice no documento _HTML_ que iremos produzir.

```python
def get_html_author_index(data):
    index = sorted(get_author_index_dict(data).items())
    alphabet_order = sorted(set(c[0][0] for c in index))
    string_ls = [html_enclose('h2','Author Index')]
    i = 0
    string_ls.append(html_enclose('h3',alphabet_order[i]))
    for author,citation_keys in index:
        if author[0] != alphabet_order[i]:
            i += 1
            string_ls.append(html_enclose('h3',alphabet_order[i]))
        citation_keys_str = ', '.join(citation_keys)
        string_ls.append(html_enclose('p',f'{author}, {citation_keys_str}'))
    return '\n'.join(string_ls)
```

Parte do _HTML_ gerado:

![](auth_ind.png)

## Execução pela linha de comandos

Este bloco é utilizado para executar o programa pela linha de comandos.

```python, evaluate = False
if __name__ == '__main__':
    import sys
    import os.path
```

Para facilitar a realização de testes deixamos o valor _standard_ do `filename` para o ficheiro exemplo.

```python, evaluate = False
    filename = sys.argv[1] if len(sys.argv) > 1 else BIB_EXAMPLE_FILENAME
    assert os.path.isfile(filename)
```

Novamente, para facilitar a realização de testes (executar sem passar o argumento com o nome do autor) escolhemos a autora Daniela da Cruz que está presente no ficheiro `exemplo-utf8.bib` com o intuito de gerar o grafo conforme [(R5)](#R5).


```python, evaluate = False
    if len(sys.argv) < 3:
        author_name = 'Daniela da Cruz'
    else:
        author_name = sys.argv[2]
    solve(author_name,filename)

```

## Conclusão

Através deste projeto foi possível expandir as nossas competências intelectuais sobre o tópico de estudo: Expressões Regulares (ER) que nos possibilitou desenvolver um processador $Bib\TeX$ utilizando a linguagem _Pyhton_ para extrair informações relavantes. Além disso, aumentamos a nossa familiaridade com _HTML_ pois dispusemos as informações coletadas numa página _web_, onde inserimos um grafo gerado usando a linguagem _Dot_.

Consideramos que o produto final cumpre os [requisitos](#req).

Este projeto foi desafiante (pela complexidade do $La\TeX$) e enriquecedor (pela variedade de linguagens usadas) para cada um de nós, uma vez que tivemos a oportunidade de expandir, aprofundar e aperfeiçoar os nossos conhecimentos.

### Pontos que podemos melhorar

* estruturação do programa